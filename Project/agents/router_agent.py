"""
router_agent.py ‚Äî Agent ph√¢n lo·∫°i query v·ªõi context processing
UPDATED: Context-aware query rewriting cho follow-up questions
"""

import logging
import json
import re
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from Project.agents.base_agent import BaseAgent
from Project.state.state import AgentState

logger = logging.getLogger(__name__)


class RouterAgent(BaseAgent):
    """Agent ph√¢n lo·∫°i c√¢u h·ªèi du l·ªãch B√£i Ch√°y v·ªõi context processing."""

    @property
    def context_processing_prompt(self) -> str:
        """System prompt cho context processing."""
        return """B·∫°n l√† chuy√™n gia ph√¢n t√≠ch ng·ªØ c·∫£nh h·ªôi tho·∫°i.

NHI·ªÜM V·ª§:
Ph√¢n t√≠ch c√¢u h·ªèi hi·ªán t·∫°i v√† l·ªãch s·ª≠ h·ªôi tho·∫°i ƒë·ªÉ:
1. X√°c ƒë·ªãnh xem c√≥ ph·∫£i c√¢u h·ªèi follow-up kh√¥ng
2. L√†m r√µ c√¢u h·ªèi v·ªõi ƒë·∫ßy ƒë·ªß ng·ªØ c·∫£nh

Y√äU C·∫¶U QUAN TR·ªåNG:
- Ph√¢n t√≠ch xem c√¢u h·ªèi c√≥ ph·∫£i follow-up (ti·∫øp theo cu·ªôc tr√≤ chuy·ªán tr∆∞·ªõc) kh√¥ng
- Truy v·∫øt l·ªãch s·ª≠ ƒë·ªÉ x√°c ƒë·ªãnh ch√≠nh x√°c ƒë·ªëi t∆∞·ª£ng ƒë∆∞·ª£c nh·∫Øc t·ªõi
- ƒê·∫∑c bi·ªát ch√∫ √Ω c√°c c·ª•m t·ª´:
  * ƒê·∫°i t·ª´: "n√≥", "√Ω tr√™n", "c√°i ƒë√≥", "ph·∫ßn n√†y", "th√†nh ph·∫ßn th·ª© X"
  * X√°c nh·∫≠n: "OK", "c√≥", "ƒë∆∞·ª£c", "ƒë·ªìng √Ω"
  * Y√™u c·∫ßu ti·∫øp: "chi ti·∫øt", "h√£y h∆∞·ªõng d·∫´n", "ti·∫øp t·ª•c", "n√≥i th√™m"
  * Ch·ªâ ƒë·ªãnh: "c√°i th·ª© nh·∫•t", "option 2", "s·ªë 3"
  
- N·∫øu l·ªãch s·ª≠ c√≥ DANH S√ÅCH ƒê√ÅNH S·ªê ‚Üí √°nh x·∫° theo ƒê√öNG TH·ª® T·ª∞
- N·∫øu c√≥ y√™u c·∫ßu h√†nh ƒë·ªông kh√¥ng c·ª• th·ªÉ ‚Üí d·ª±a v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i l√†m r√µ y√™u c·∫ßu
- Vi·∫øt l·∫°i c√¢u h·ªèi (contextualized_question) b·∫±ng TI·∫æNG VI·ªÜT ƒê·∫¶Y ƒê·ª¶ ‚Äì R√ï NGHƒ®A ‚Äì C√ì NG·ªÆ C·∫¢NH

ƒê·∫£m b·∫£o c√¢u h·ªèi ƒë∆∞·ª£c l√†m r√µ (contextualized_question) ph·∫£i c√≥:
- ƒê·ªêI T∆Ø·ª¢NG c·ª• th·ªÉ l√† g√¨ (t√™n kh√°ch s·∫°n, tour, ƒë·ªãa ƒëi·ªÉm...)
- H√ÄNH ƒê·ªòNG c·ª• th·ªÉ l√† g√¨ (t√¨m, ƒë·∫∑t, h·ªèi v·ªÅ...)
- Trong NG·ªÆ C·∫¢NH c·ª• th·ªÉ l√† g√¨ (gi√°, v·ªã tr√≠, th·ªùi gian...)

N·∫øu kh√¥ng ph·∫£i follow-up: 
- contextualized_question = c√¢u h·ªèi g·ªëc
- context_summary = "C√¢u h·ªèi ƒë·ªôc l·∫≠p"

OUTPUT FORMAT (JSON):
{{
  "is_followup": true ho·∫∑c false,
  "contextualized_question": "C√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c l√†m r√µ r·∫•t c·ª• th·ªÉ ho·∫∑c c√¢u h·ªèi g·ªëc",
  "context_summary": "T√≥m t·∫Øt ng·∫Øn g·ªçn ng·ªØ c·∫£nh B·∫∞NG TI·∫æNG VI·ªÜT",
  "detected_references": {{
    "pronouns": ["n√≥", "c√°i ƒë√≥"...],
    "numbers": ["th·ª© 1", "s·ªë 2"...],
    "actions": ["chi ti·∫øt", "ƒë·∫∑t lu√¥n"...]
  }},
  "resolved_entities": {{
    "hotel_name": "T√™n kh√°ch s·∫°n n·∫øu c√≥",
    "tour_name": "T√™n tour n·∫øu c√≥",
    "service_id": "ID d·ªãch v·ª• n·∫øu x√°c ƒë·ªãnh ƒë∆∞·ª£c"
  }}
}}

V√ç D·ª§:

Example 1 - Follow-up v·ªõi ƒë·∫°i t·ª´:
Input:
  Question: "N√≥ gi√° bao nhi√™u?"
  History: "Assistant: ƒê√¢y l√† kh√°ch s·∫°n M∆∞·ªùng Thanh 4 sao..."
Output:
{{
  "is_followup": true,
  "contextualized_question": "Kh√°ch s·∫°n M∆∞·ªùng Thanh 4 sao gi√° bao nhi√™u?",
  "context_summary": "H·ªèi gi√° kh√°ch s·∫°n M∆∞·ªùng Thanh ƒë∆∞·ª£c nh·∫Øc ·ªü tin nh·∫Øn tr∆∞·ªõc",
  "detected_references": {{"pronouns": ["n√≥"]}},
  "resolved_entities": {{"hotel_name": "M∆∞·ªùng Thanh"}}
}}

Example 2 - Follow-up v·ªõi s·ªë th·ª© t·ª±:
Input:
  Question: "C√°i th·ª© 2 ƒëi"
  History: "Assistant: C√≥ 3 tour: 1. Tour H·∫° Long 1 ng√†y, 2. Tour H·∫° Long 2 ng√†y 1 ƒë√™m, 3. Tour..."
Output:
{{
  "is_followup": true,
  "contextualized_question": "Cho t√¥i th√¥ng tin chi ti·∫øt v·ªÅ Tour H·∫° Long 2 ng√†y 1 ƒë√™m",
  "context_summary": "Ch·ªçn tour th·ª© 2 trong danh s√°ch ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t",
  "detected_references": {{"numbers": ["th·ª© 2"]}},
  "resolved_entities": {{"tour_name": "Tour H·∫° Long 2 ng√†y 1 ƒë√™m"}}
}}

Example 3 - Follow-up v·ªõi x√°c nh·∫≠n:
Input:
  Question: "OK, ƒë·∫∑t lu√¥n"
  History: "User: T√¥i mu·ªën kh√°ch s·∫°n g·∫ßn bi·ªÉn. Assistant: Kh√°ch s·∫°n Novotel..."
Output:
{{
  "is_followup": true,
  "contextualized_question": "ƒê·∫∑t ph√≤ng kh√°ch s·∫°n Novotel g·∫ßn bi·ªÉn",
  "context_summary": "X√°c nh·∫≠n ƒë·∫∑t kh√°ch s·∫°n Novotel ƒë∆∞·ª£c gi·ªõi thi·ªáu",
  "detected_references": {{"actions": ["ƒë·∫∑t lu√¥n"]}},
  "resolved_entities": {{"hotel_name": "Novotel"}}
}}

Example 4 - C√¢u h·ªèi ƒë·ªôc l·∫≠p:
Input:
  Question: "T√¨m kh√°ch s·∫°n 4 sao g·∫ßn bi·ªÉn"
  History: ""
Output:
{{
  "is_followup": false,
  "contextualized_question": "T√¨m kh√°ch s·∫°n 4 sao g·∫ßn bi·ªÉn",
  "context_summary": "C√¢u h·ªèi ƒë·ªôc l·∫≠p",
  "detected_references": {{}},
  "resolved_entities": {{}}
}}

NGUY√äN T·∫ÆC:
- LU√îN LU√îN tr·∫£ v·ªÅ JSON h·ª£p l·ªá
- contextualized_question PH·∫¢I r√µ r√†ng, c√≥ th·ªÉ search ƒë∆∞·ª£c
- N·∫øu kh√¥ng ch·∫Øc ch·∫Øn ‚Üí is_followup = false
- ∆Øu ti√™n th√¥ng tin g·∫ßn nh·∫•t trong l·ªãch s·ª≠"""

    @property
    def classification_prompt(self) -> str:
        """System prompt cho classification."""
        return """B·∫°n l√† tr·ª£ l√Ω ph√¢n lo·∫°i c√¢u h·ªèi du l·ªãch B√£i Ch√°y.

Ph√¢n lo·∫°i c√¢u h·ªèi th√†nh 1 trong 5 lo·∫°i:
- "hello": L·ªùi ch√†o, ch√†o h·ªèi, gi·ªõi thi·ªáu ban ƒë·∫ßu
- "human": Kh√°ch cung c·∫•p th√¥ng tin c√° nh√¢n (t√™n, SƒêT, ng√†y check-in/out)
- "tourism": T√¨m tour, ƒëi·ªÉm ƒë·∫øn, kh√°ch s·∫°n, nh√† h√†ng, gi√° c·∫£
- "document": H·ªèi v·ªÅ quy ƒë·ªãnh, khi·∫øu n·∫°i, th·ªß t·ª•c, ch√≠nh s√°ch
- "booking": Kh√°ch mu·ªën ƒë·∫∑t d·ªãch v·ª• (sau khi ƒë√£ c√≥ ƒë·ªß th√¥ng tin)

V√≠ d·ª•:
- "Xin ch√†o" ‚Üí hello
- "T√™n t√¥i l√† Nguy·ªÖn VƒÉn A" ‚Üí human
- "T√¨m kh√°ch s·∫°n 4 sao g·∫ßn bi·ªÉn" ‚Üí tourism
- "Kh√°ch s·∫°n M∆∞·ªùng Thanh gi√° bao nhi√™u?" ‚Üí tourism
- "Quy ƒë·ªãnh h·ªßy tour nh∆∞ th·∫ø n√†o?" ‚Üí document
- "ƒê·∫∑t lu√¥n tour n√†y" ‚Üí booking

CH·ªà TR·∫¢ V·ªÄ 1 T·ª™: hello, human, tourism, document, ho·∫∑c booking
KH√îNG GI·∫¢I TH√çCH, CH·ªà TR·∫¢ V·ªÄ T·ª™ KH√ìA."""

    @property
    def system_prompt(self) -> str:
        """Backward compatibility."""
        return self.classification_prompt

    def process(self, state: AgentState) -> AgentState:
        """
        Ph√¢n lo·∫°i query v·ªõi context processing:
        1. Ph√¢n t√≠ch context v√† l√†m r√µ c√¢u h·ªèi
        2. Ph√¢n lo·∫°i query type
        3. Update state v·ªõi contextualized question
        """
        logger.info("üîÄ Router Agent analyzing query...")

        # Step 1: Context Processing
        context_result = self._process_context(state)

        if context_result:
            # Update state v·ªõi contextualized question
            original_query = state["user_query"]
            contextualized_query = context_result.get("contextualized_question", original_query)

            # Log context analysis
            if context_result.get("is_followup"):
                logger.info(f"üìù Follow-up detected!")
                logger.info(f"   Original: {original_query}")
                logger.info(f"   Contextualized: {contextualized_query}")
                logger.info(f"   Summary: {context_result.get('context_summary')}")

            # Store context info in state
            state["contextualized_query"] = contextualized_query
            state["context_info"] = context_result

            # Use contextualized query for classification
            query_for_classification = contextualized_query
        else:
            # No context processing, use original
            query_for_classification = state["user_query"]
            state["contextualized_query"] = state["user_query"]
            state["context_info"] = {
                "is_followup": False,
                "context_summary": "C√¢u h·ªèi ƒë·ªôc l·∫≠p"
            }

        # Step 2: Build customer info context
        customer_info = state.get("customer_info", {})
        context_info_text = ""

        if customer_info:
            has_name = customer_info.get("name") is not None
            has_phone = customer_info.get("phone") is not None
            has_checkin = customer_info.get("checkin") is not None
            has_checkout = customer_info.get("checkout") is not None

            context_info_text = f"""
Th√¥ng tin kh√°ch h√†ng hi·ªán c√≥:
- T√™n: {"C√≥" if has_name else "Ch∆∞a c√≥"}
- SƒêT: {"C√≥" if has_phone else "Ch∆∞a c√≥"}
- Check-in: {"C√≥" if has_checkin else "Ch∆∞a c√≥"}
- Check-out: {"C√≥" if has_checkout else "Ch∆∞a c√≥"}
"""

        # Step 3: Classification
        response = self.llm.invoke([
            SystemMessage(content=self.classification_prompt),
            HumanMessage(
                content=(
                    f"Ph√¢n lo·∫°i c√¢u h·ªèi sau:\n{query_for_classification}\n\n"
                    f"{context_info_text}"
                )
            ),
        ])
        raw = response.content.strip().lower()

        # Determine query type
        if "hello" in raw:
            query_type = "hello"
        elif "human" in raw:
            query_type = "human"
        elif "document" in raw:
            query_type = "document"
        elif "booking" in raw:
            query_type = "booking"
        else:
            query_type = "tourism"

        logger.info(f"‚úÖ Query type: {query_type}")
        state["query_type"] = query_type
        state["messages"].append(AIMessage(
            content=f"[Query classified as: {query_type}]"
        ))

        return state

    def _process_context(self, state: AgentState) -> dict:
        """
        X·ª≠ l√Ω context v√† l√†m r√µ c√¢u h·ªèi follow-up.

        Returns:
            Dict v·ªõi is_followup, contextualized_question, context_summary
        """
        try:
            # Build conversation history
            history_text = self._build_history_text(state)

            # If no history, no context needed
            if not history_text or len(history_text.strip()) < 10:
                return {
                    "is_followup": False,
                    "contextualized_question": state["user_query"],
                    "context_summary": "C√¢u h·ªèi ƒë·ªôc l·∫≠p"
                }

            # Invoke LLM for context analysis
            response = self.llm.invoke([
                SystemMessage(content=self.context_processing_prompt),
                HumanMessage(
                    content=(
                        f"ƒê·∫ßu v√†o:\n"
                        f"C√¢u h·ªèi hi·ªán t·∫°i: \"{state['user_query']}\"\n"
                        f"L·ªãch s·ª≠ h·ªôi tho·∫°i:\n{history_text}\n\n"
                        "H√£y ph√¢n t√≠ch v√† tr·∫£ l·ªùi theo ƒë·ªãnh d·∫°ng JSON."
                    )
                ),
            ])

            # Parse JSON response
            result = self._parse_context_response(response.content)

            if result:
                return result
            else:
                # Fallback
                logger.warning("‚ö†Ô∏è Context processing failed, using original query")
                return {
                    "is_followup": False,
                    "contextualized_question": state["user_query"],
                    "context_summary": "Kh√¥ng th·ªÉ ph√¢n t√≠ch context"
                }

        except Exception as e:
            logger.error(f"‚ùå Context processing error: {e}")
            return {
                "is_followup": False,
                "contextualized_question": state["user_query"],
                "context_summary": f"L·ªói x·ª≠ l√Ω context: {e}"
            }

    def _build_history_text(self, state: AgentState, max_turns: int = 3) -> str:
        """
        Build conversation history text t·ª´ messages.

        Args:
            state: Agent state
            max_turns: S·ªë l∆∞·ª£t h·ªôi tho·∫°i t·ªëi ƒëa (default: 3)

        Returns:
            Formatted history text
        """
        messages = state.get("messages", [])

        if not messages:
            return ""

        # Take last N messages
        recent_messages = messages[-(max_turns * 2):]  # *2 v√¨ c√≥ c·∫£ user v√† assistant

        history_lines = []
        for msg in recent_messages:
            if hasattr(msg, "content"):
                # Skip internal messages
                if msg.content.startswith("[") and msg.content.endswith("]"):
                    continue

                role = "User" if msg.__class__.__name__ == "HumanMessage" else "Assistant"

                # Truncate long messages
                content = msg.content
                if len(content) > 500:
                    content = content[:497] + "..."

                history_lines.append(f"{role}: {content}")

        return "\n".join(history_lines)

    def _parse_context_response(self, response_text: str) -> dict:
        """
        Parse JSON response t·ª´ LLM.

        Returns:
            Parsed dict ho·∫∑c None n·∫øu invalid
        """
        try:
            # Try to find JSON in response
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)

            if json_match:
                result = json.loads(json_match.group())

                # Validate required fields
                if "is_followup" in result and "contextualized_question" in result:
                    return result

            # Try direct parse
            result = json.loads(response_text)

            if "is_followup" in result and "contextualized_question" in result:
                return result

            return None

        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON parse error: {e}")
            return None